{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Summarizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VsGsAZ0iRf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl7U98qsNQ5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Reviews_slice.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjKxPlk_yr3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop_duplicates()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlpbvpNdy3iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.dropna()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzWZriClNTvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6rjzMDmNY73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUiRjMUlOFuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a8e7f84f-3bc7-4d72-bd92-52740bc35820"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJb-y_A6OFnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a7e6b2d9-24af-4a5c-e069-a1df1af23dc4"
      },
      "source": [
        "print(stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'both', \"don't\", 'hadn', 'should', 'has', 'between', 'above', 'now', 'while', 'doesn', 'if', 'he', 're', \"aren't\", 'that', 'be', 'd', 'those', 'some', 'my', 'out', 'o', 'yourself', 'just', 'was', 'most', 'haven', \"hasn't\", \"you'd\", 'because', 'off', \"won't\", 'she', 'its', 'll', 'had', 'hers', 'to', 'been', 'did', 'myself', 't', 'shouldn', 'mightn', 'such', 'ourselves', \"you've\", 'after', 'all', 's', 'will', 'whom', 'only', 'yourselves', 'the', 'below', 'm', 'am', 'what', 'over', \"mustn't\", 'about', 'it', \"weren't\", 'mustn', 'yours', 'himself', 'from', 'aren', 'under', 'being', 'hasn', 'and', 'them', 'on', \"that'll\", 'didn', 'isn', 'but', \"mightn't\", 'own', 'until', 'who', \"isn't\", \"should've\", 'further', \"couldn't\", 'when', 'up', 'ma', 'other', 'with', \"shan't\", 'shan', 'then', 'same', 'which', 'through', \"haven't\", 'y', 'where', \"you're\", 'wouldn', \"doesn't\", 'against', \"didn't\", 'once', 'can', 'or', 'as', \"it's\", 'needn', 'have', 'an', 'we', 'their', 'are', 'i', 'here', 'of', 'our', 'too', 'were', 'herself', 'why', 'any', 've', 'in', \"wouldn't\", 'not', \"needn't\", 'these', 'weren', 'doing', 'nor', 'themselves', \"wasn't\", 'into', \"shouldn't\", 'than', 'ours', 'having', 'during', 'no', 'there', 'me', 'so', 'wasn', 'before', 'itself', 'you', 'theirs', 'how', \"she's\", 'a', 'your', 'do', 'his', 'down', 'him', 'very', 'at', 'few', 'her', 'this', \"you'll\", 'by', 'for', 'more', 'each', 'couldn', 'don', \"hadn't\", 'ain', 'again', 'they', 'is', 'does', 'won'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tMYAja-NcIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_cleaner(text):\n",
        "    new_string = text.lower()\n",
        "    new_string = BeautifulSoup(new_string, 'lxml').text\n",
        "    new_string = re.sub(r'\\([^)]*\\)', '', new_string)\n",
        "    new_string = re.sub('\"', '', new_string)\n",
        "    new_string = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_string.split(\" \")])\n",
        "    new_string = re.sub(r\"'s\\b\", \"\", new_string)\n",
        "    new_string = re.sub(\"[^a-zA-Z]\", \" \", new_string)\n",
        "    tokens = [w for w in new_string.split() if not w in stop_words]\n",
        "    long_words = []\n",
        "    for i in tokens:\n",
        "        if(len(i) >= 3):\n",
        "            long_words.append(i)\n",
        "    return (' '.join(long_words)).strip()\n",
        "\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t))\n",
        "    \n",
        "def summary_cleaner(text):\n",
        "    new_string = re.sub('\"', '', text)\n",
        "    new_string = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_string.split(' ')])\n",
        "    new_string = re.sub(r\"'s\\b\", '', new_string)\n",
        "    new_string = re.sub('[^a-zA-Z]', ' ', new_string)\n",
        "    new_string = new_string.lower()\n",
        "    tokens = new_string.split()\n",
        "    new_string = ''\n",
        "    for i in tokens:\n",
        "        if(len(i) > 1):\n",
        "            new_string = new_string + i + ' '\n",
        "    return new_string\n",
        "\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPlYGaSaOij9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9rzVfl0zs0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea9f5c71-e8e2-4ccb-e28f-7d0c3d03377e"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ebNe4vOoV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_' + x + '_END_')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyYvJY0AOwCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0795066f-c083-475f-8f7a-77b831ff65f8"
      },
      "source": [
        "print(data['cleaned_summary'][1])\n",
        "print(data['cleaned_text'][1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_START_not as advertised _END_\n",
            "product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3jqwSEBO3tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 80\n",
        "max_len_summary = 10\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(data['cleaned_text'], data['cleaned_summary'], test_size = 0.1, random_state = 0, shuffle = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4QzwTP9O86J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(X_train))\n",
        "X_train_encoded = x_tokenizer.texts_to_sequences(X_train)\n",
        "X_train_encoded = pad_sequences(X_train_encoded, maxlen = max_len, padding = 'post')\n",
        "X_val_encoded = x_tokenizer.texts_to_sequences(X_val)\n",
        "X_val_encoded = pad_sequences(X_val_encoded, maxlen = max_len, padding = 'post')\n",
        "x_voc_size = len(x_tokenizer.word_index) + 1\n",
        "\n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "y_train_encoded = y_tokenizer.texts_to_sequences(y_train)\n",
        "y_val_encoded = y_tokenizer.texts_to_sequences(y_val)\n",
        "y_train_encoded = pad_sequences(y_train_encoded, maxlen = max_len_summary, padding = 'post')\n",
        "y_val_encoded = pad_sequences(y_val_encoded, maxlen = max_len_summary, padding = 'post')\n",
        "y_voc_size = len(y_tokenizer.word_index) + 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJdOhZSnPApV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 500"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-cg40n9PDq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = layers.Input(shape = (max_len,))\n",
        "enc_emb = layers.Embedding(x_voc_size, latent_dim, trainable = True)(encoder_inputs)\n",
        "\n",
        "encoder_lstm1 = layers.LSTM(latent_dim, return_sequences = True, return_state = True)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "encoder_lstm2 = layers.LSTM(latent_dim, return_sequences = True, return_state = True)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "encoder_lstm3 = layers.LSTM(latent_dim, return_state = True, return_sequences = True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)\n",
        "\n",
        "decoder_inputs = layers.Input(shape = (None,))\n",
        "dec_emb_layer = layers.Embedding(y_voc_size, latent_dim, trainable = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = layers.LSTM(latent_dim, return_sequences = True, return_state = True)\n",
        "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state = [state_h, state_c])\n",
        "\n",
        "attn_layer = layers.Attention()\n",
        "attn_output = attn_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "decoder_concat_input = layers.Concatenate(axis = -1, name = 'concat_layer')([decoder_outputs, attn_output])\n",
        "\n",
        "decoder_dense = layers.TimeDistributed(layers.Dense(y_voc_size, activation = 'softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Bmo3lGFUUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34853cd5-ee7c-4b52-df13-12476421004b"
      },
      "source": [
        "attn_output.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, None, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAYOzQCkPSCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "44325637-6e41-40aa-9855-681786cc25e4"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 80, 500)      25986000    input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  [(None, 80, 500), (N 2002000     embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_17 (LSTM)                  [(None, 80, 500), (N 2002000     lstm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, None, 500)    7102500     input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_18 (LSTM)                  [(None, 80, 500), (N 2002000     lstm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_19 (LSTM)                  [(None, None, 500),  2002000     embedding_9[0][0]                \n",
            "                                                                 lstm_18[0][1]                    \n",
            "                                                                 lstm_18[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_4 (Attention)         (None, None, 500)    0           lstm_19[0][0]                    \n",
            "                                                                 lstm_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_19[0][0]                    \n",
            "                                                                 attention_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, None, 14205)  14219205    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 55,315,705\n",
            "Trainable params: 55,315,705\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2gOOTzePWiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'rmsprop', loss = 'sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp8n65uDPY-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "c80d543c-0882-4844-9fc9-53c2e99af4da"
      },
      "source": [
        "history = model.fit([X_train_encoded, y_train_encoded[:, :-1]], y_train_encoded.reshape(y_train_encoded.shape[0], y_train_encoded.shape[1], 1)[:, 1:, :], epochs = 50, callbacks = [es], \n",
        "                     batch_size = 512, validation_data = ([X_val_encoded, y_val_encoded[:, :-1]], y_val_encoded.reshape(y_val.shape[0], y_val_encoded.shape[1], 1)[:, 1:]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "176/176 [==============================] - 87s 493ms/step - loss: 3.1525 - val_loss: 2.7789\n",
            "Epoch 2/50\n",
            "176/176 [==============================] - 86s 487ms/step - loss: 2.6673 - val_loss: 2.5232\n",
            "Epoch 3/50\n",
            "176/176 [==============================] - 85s 486ms/step - loss: 2.4661 - val_loss: 2.3881\n",
            "Epoch 4/50\n",
            "176/176 [==============================] - 85s 483ms/step - loss: 2.3321 - val_loss: 2.3158\n",
            "Epoch 5/50\n",
            "176/176 [==============================] - 85s 483ms/step - loss: 2.2284 - val_loss: 2.2582\n",
            "Epoch 6/50\n",
            "176/176 [==============================] - 85s 485ms/step - loss: 2.1366 - val_loss: 2.2202\n",
            "Epoch 7/50\n",
            "176/176 [==============================] - 85s 484ms/step - loss: 2.0527 - val_loss: 2.1764\n",
            "Epoch 8/50\n",
            "176/176 [==============================] - 85s 485ms/step - loss: 1.9733 - val_loss: 2.1431\n",
            "Epoch 9/50\n",
            "176/176 [==============================] - 85s 486ms/step - loss: 1.8970 - val_loss: 2.1249\n",
            "Epoch 10/50\n",
            "176/176 [==============================] - 85s 485ms/step - loss: 1.8246 - val_loss: 2.1049\n",
            "Epoch 11/50\n",
            "176/176 [==============================] - 86s 486ms/step - loss: 1.7530 - val_loss: 2.0892\n",
            "Epoch 12/50\n",
            "176/176 [==============================] - 85s 485ms/step - loss: 1.6846 - val_loss: 2.0960\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnP7Mr0iIXPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSwAKbwGQgfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index = y_tokenizer.word_index\n",
        "reverse_source_word_index = x_tokenizer.word_index\n",
        "target_word_index = y_tokenizer.word_index"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTBd-z2LMdPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index = y_tokenizer.index_word"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx66LUKPKuUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "46bfcbbc-ef23-4931-c04e-88b0382bab70"
      },
      "source": [
        "decoder_lstm.get_weights()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.09285009,  0.01536157,  0.0172569 , ..., -0.09856436,\n",
              "         -0.27567434,  0.11334325],\n",
              "        [-0.0981838 ,  0.15075378, -0.06689165, ...,  0.13516389,\n",
              "          0.35894108, -0.1623892 ],\n",
              "        [ 0.12607414,  0.10584345, -0.13180818, ..., -0.0077575 ,\n",
              "         -0.06649654, -0.5150198 ],\n",
              "        ...,\n",
              "        [-0.1071116 ,  0.01685378,  0.00341256, ...,  0.05633232,\n",
              "          0.14892916,  0.1066574 ],\n",
              "        [ 0.02377029,  0.01162305, -0.02431881, ..., -0.05061675,\n",
              "         -0.10206601, -0.08854173],\n",
              "        [-0.06321345, -0.03513729,  0.05923058, ...,  0.07705364,\n",
              "          0.22979861, -0.18189426]], dtype=float32),\n",
              " array([[ 0.03627593,  0.42709506,  0.04562321, ...,  0.6294713 ,\n",
              "          0.36680633, -0.2599982 ],\n",
              "        [ 0.06720988,  0.05094253, -0.01364066, ..., -0.0529791 ,\n",
              "          0.01087383, -0.00882576],\n",
              "        [ 0.04186444, -0.01414681,  0.21144482, ..., -0.04258341,\n",
              "          0.00069788,  0.12477817],\n",
              "        ...,\n",
              "        [ 0.03688895, -0.00161205,  0.01731875, ..., -0.02810247,\n",
              "          0.02830306, -0.0667143 ],\n",
              "        [ 0.02268406,  0.11365835,  0.09469083, ...,  0.05951432,\n",
              "          0.17713481,  0.02334274],\n",
              "        [-0.00787293, -0.40581018, -0.05352976, ..., -0.6661299 ,\n",
              "         -0.29411146,  0.35148364]], dtype=float32),\n",
              " array([ 0.12913884,  0.3999672 ,  0.14186573, ...,  0.33204907,\n",
              "         0.4995263 , -0.28472462], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5KlmeKzL18J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(inputs = encoder_inputs, outputs = [encoder_outputs, state_h, state_c])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYOqlVHIGm8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_state_input_h = layers.Input(shape = (latent_dim,))\n",
        "decoder_state_input_c = layers.Input(shape = (latent_dim,))\n",
        "decoder_hidden_state_input = layers.Input(shape = (max_len, latent_dim))\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = [decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
        "decoder_inf_concat = layers.Concatenate(axis = -1, name = 'concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
        "                      [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIDIPcUWIpnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1KdnjqQGwDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequence = data['cleaned_text'][9876]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ2GWLgpDgSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tokens = x_tokenizer.texts_to_sequences([test_sequence])\n",
        "test_seq = pad_sequences(test_tokens, maxlen = max_len, padding = 'post')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmOEB_cYFFei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e_out, e_h, e_c = encoder_model.predict(test_seq)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxzosRlGFbvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_seq = np.zeros((1, 1))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP_YVHtrI13A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_seq[0, 0] = target_word_index['start']"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UcKoTC8MM5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHbq0LhdIGvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "050cf30f-f015-457d-b319-b48c31f30b42"
      },
      "source": [
        "target_seq"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH82SusNF1fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_condition = False\n",
        "decoded_sentence = ''\n",
        "while not stop_condition:\n",
        "  output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "  sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "  sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "  if (sampled_token != 'end'):\n",
        "    decoded_sentence += \" \"+sampled_token\n",
        "  if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "    stop_condition = True\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  target_seq[0, 0] = sampled_token_index\n",
        "  e_h, e_c = h, c"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nLZR5G-MuAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49813a8f-e93d-41a0-b184-c5e6a357fd62"
      },
      "source": [
        "print(decoded_sentence)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " great gift\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGjfovXgMzQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c1b3976a-823b-42fa-f6a1-a666bd501460"
      },
      "source": [
        "print(data['Text'][9876])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I got these for my boyfriend for Christmas. They are a bit smaller then what i figured they would be from the box, I havent given them to him yet of course but i am sure we will have fun trying them. The box came two day earlier then what amazon said they would come which is nice :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5fxt7cmNUZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "838fec18-953d-4637-8087-ab6f4a02e58b"
      },
      "source": [
        "print(data['Summary'][9876])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "very cool gift\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJNQf_Y4FvEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('text_model.h5')"
      ],
      "execution_count": 84,
      "outputs": []
    }
  ]
}